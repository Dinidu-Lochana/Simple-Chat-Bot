{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRnQI3kbMzbK"
      },
      "source": [
        "# **Chat Bot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Du1Va-pLa-C",
        "outputId": "30cc7cef-6c5f-483a-f3e4-dcd8b2fa9f27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chromadb 0.5.23 requires tokenizers<=0.20.3,>=0.13.2, but you have tokenizers 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch -q\n",
        "!pip install transformers -q\n",
        "!pip install numpy -q\n",
        "!pip install langchain -q\n",
        "!pip install langchain_community -q\n",
        "!pip install langchain-chroma -q\n",
        "!pip install sentence_transformers -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8__uIwhgt3zL",
        "outputId": "4e559353-75c0-4eb7-ddd7-e77d829163af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping protobuf as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tokenizers as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y protobuf tokenizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "FahdDYWIsIwF",
        "outputId": "cb78276c-b6ce-4ac3-9778-4a9c1525eaa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting protobuf==3.20.3\n",
            "  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Collecting tokenizers==0.20.3\n",
            "  Using cached tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers==0.20.3) (0.27.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (2023.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.20.3) (2024.12.14)\n",
            "Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Using cached tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Installing collected packages: protobuf, tokenizers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "opentelemetry-proto 1.29.0 requires protobuf<6.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "transformers 4.47.1 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3 tokenizers-0.20.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "4defcef773e74a27acd0a14c00ab34cb",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install protobuf==3.20.3 tokenizers==0.20.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kFMljzGenqb"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.2 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XKTCNB8sMLH",
        "outputId": "f491a17d-c760-47f3-d6fd-0b0757b87531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Collecting langchain<0.4.0,>=0.3.13 (from langchain_community)\n",
            "  Using cached langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.28)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.147)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.5.20)\n",
            "Requirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.115.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.10.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.34.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.4)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.68.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (31.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.41.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.13->langchain_community) (0.3.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.20.3)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n",
            "  Using cached protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.27.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (14.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
            "Using cached langchain-0.3.13-py3-none-any.whl (1.0 MB)\n",
            "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Using cached protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Installing collected packages: protobuf, tokenizers, langchain\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.2\n",
            "    Uninstalling langchain-0.3.2:\n",
            "      Successfully uninstalled langchain-0.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.3.13 protobuf-5.29.2 tokenizers-0.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers numpy langchain_community langchain-chroma sentence_transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycZ5wte2tAYn",
        "outputId": "e7984e48-5231-45e8-b118-20c5606ffc8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.147)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.5.20)\n",
            "Requirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.115.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.34.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.4)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.68.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (31.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.41.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.29.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (14.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch transformers numpy langchain langchain_community langchain-chroma sentence_transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtYzS77Rs3C3",
        "outputId": "7f70de99-da1c-4089-9045-2d82e28b937a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: protobuf\n",
            "Version: 5.29.2\n",
            "Summary: \n",
            "Home-page: https://developers.google.com/protocol-buffers/\n",
            "Author: protobuf@googlegroups.com\n",
            "Author-email: protobuf@googlegroups.com\n",
            "License: 3-Clause BSD License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: google-ai-generativelanguage, google-api-core, google-cloud-aiplatform, google-cloud-bigquery-connection, google-cloud-bigquery-storage, google-cloud-bigtable, google-cloud-datastore, google-cloud-firestore, google-cloud-functions, google-cloud-iam, google-cloud-language, google-cloud-pubsub, google-cloud-resource-manager, google-cloud-translate, google-generativeai, googleapis-common-protos, grpc-google-iam-v1, grpcio-status, onnxruntime, opentelemetry-proto, orbax-checkpoint, proto-plus, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-metadata, wandb\n",
            "---\n",
            "Name: tokenizers\n",
            "Version: 0.21.0\n",
            "Summary: \n",
            "Home-page: https://github.com/huggingface/tokenizers\n",
            "Author: Anthony MOI <m.anthony.moi@gmail.com>\n",
            "Author-email: Nicolas Patry <patry.nicolas@protonmail.com>, Anthony Moi <anthony@huggingface.co>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: huggingface-hub\n",
            "Required-by: chromadb, langchain-huggingface, transformers\n"
          ]
        }
      ],
      "source": [
        "!pip show protobuf tokenizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n5zAATJ_W1s",
        "outputId": "48e32ebd-a472-4c48-a3d7-cbb92d122bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.27.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.3.28)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.21.0)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2023.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.1.147)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (8.5.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-huggingface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlqGMs9UD58t"
      },
      "outputs": [],
      "source": [
        "!pip install rank_bm25 -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Snge1XxQ9aTk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUM7Gb9MM5Un"
      },
      "source": [
        "# **Initialize HuggingFace LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUpIHw17MCUK"
      },
      "outputs": [],
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HUGGINGFACEHUB_API_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwfY9NIj9ZZe",
        "outputId": "55f8376d-0295-4407-ff6d-6e48df15d7c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-ed86f327c128>:3: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
            "  llm = HuggingFaceHub(\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.llms import HuggingFaceHub\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id = \"mistralai/Mistral-7B-v0.1\",\n",
        "    model_kwargs = {\"temperature\": 0.1, \"max_length\": 512},\n",
        "    huggingfacehub_api_token = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJsGSc3eN0P6"
      },
      "source": [
        "# **Initialize Embedding Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMuFyMejNtgw",
        "outputId": "9dcb42cf-9758-4867-a5f1-5a8e4b18b68a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-34f4eb17d9b2>:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSnL3qJzOrnm"
      },
      "source": [
        "# **Initialize Output Parser**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNTqVMcTOmqN"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Output parser\n",
        "output_parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwCXwtzbF3cZ"
      },
      "source": [
        "# **Load PDF Document**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iscy3iB6F-M2"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5MfMo2bGDjH"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/Deep_Learning_Machine_Learning_Updated.pdf\")\n",
        "\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5ML1CHPGimv",
        "outputId": "ff6f2f6d-18b8-4345-f21d-2aa40363ae6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntto7sp2GT02"
      },
      "source": [
        "# **Spliting Documets into Chuncks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds0yEx26GTFg"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Text Splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 400, chunk_overlap = 50)\n",
        "\n",
        "# Split\n",
        "splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDRtYyCFHHnH",
        "outputId": "3538eca8-84b1-4882-8525-aba1d38b5493"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_c2VYRTEX2-"
      },
      "source": [
        "# **Semantic Search Retriever**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxLjln2xEe01"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "vectorStore = Chroma.from_documents(\n",
        "    documents = splits,\n",
        "    embedding = embedding_model\n",
        ")\n",
        "\n",
        "VectorStoreRetriever = vectorStore.as_retriever(search_kwargs={\"k\":2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlJ9obv9E6Vs",
        "outputId": "298ba1ba-a251-4d79-e825-af1d5b81fcec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7d855b943130>, search_kwargs={'k': 2})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "VectorStoreRetriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sgb_bINE8oD"
      },
      "source": [
        "# **Keyword Search Retriever**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLVjiJqxFF2M"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import BM25Retriever\n",
        "\n",
        "KeywordRetriever = BM25Retriever.from_documents(splits)\n",
        "\n",
        "KeywordRetriever.k = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "furbUMYnFF1T",
        "outputId": "9f7e0ef6-cb51-4d29-b82d-7c3fb9cdc8bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7d855715e140>, k=2)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "KeywordRetriever\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68ooochlGCkE"
      },
      "source": [
        "# **Hybrid Search Retriver**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMIiD3RPGOuS"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=[VectorStoreRetriever, KeywordRetriever],\n",
        "    weights=[0.6, 0.4]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIXg5VUOGtMC",
        "outputId": "0d2b7cfd-d506-49bf-b64e-5e19cfd1d296"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7d855b943130>, search_kwargs={'k': 2}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7d855715e140>, k=2)], weights=[0.6, 0.4])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWPEdC7IIICt"
      },
      "source": [
        "# **Prompt Template**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN1L8aNRIBBj"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template= \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "promptTemplate = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHl9nrp_QT5e",
        "outputId": "1ef36155-b7dc-4bd2-ac1c-83886bf8afc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\nAnswer this question using the provided context only.\\n\\n{question}\\n\\nContext:\\n{context}\\n\\nAnswer:\\n'), additional_kwargs={})])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "promptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4_HjHFKI8o0"
      },
      "source": [
        "# **Chain Retriver and Prompt Template with LLM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obImUjrLIyCL"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        "    {\"context\" : ensemble_retriever, \"question\" : RunnablePassthrough()}\n",
        "    | promptTemplate\n",
        "    | llm\n",
        "    | output_parser\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9crPIQ7TJb0M"
      },
      "source": [
        "# **Invoke RAG Chain with Inputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecaa-barJXuD",
        "outputId": "0067efa6-020f-4234-a7f3-d351ece07d91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: \n",
            "Answer this question using the provided context only.\n",
            "\n",
            "What is deep learning?\n",
            "\n",
            "Context:\n",
            "[Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='interacting with their environment and receiving rewards or penalties based on their actions. This \\napproach is often employed in robotics, game playing, and autonomous vehicles. \\nWhat is Deep Learning? \\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence'), Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\napplications of machine learning and deep learning. \\nWhat is Machine Learning? \\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\nthat enable computers to perform tasks without explicit programming. The process involves training')]\n",
            "\n",
            "Answer:\n",
            "Deep learning is a subset of machine learning that employs neural networks with many layers (hence the name \"deep\") to learn complex patterns in data. It is a powerful tool for solving a wide range of problems, including image recognition, natural language processing, and speech recognition.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = chain.invoke(\"What is deep learning?\")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGr-PrnSJpx7",
        "outputId": "6c280533-9ddc-4c6f-e0bf-4a91f00c8b8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human: \n",
            "Answer this question using the provided context only.\n",
            "\n",
            "What is Machine Learning?\n",
            "\n",
            "Context:\n",
            "[Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\napplications of machine learning and deep learning. \\nWhat is Machine Learning? \\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\nthat enable computers to perform tasks without explicit programming. The process involves training'), Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='models on datasets to identify patterns and make predictions or decisions. \\nTypes of Machine Learning \\nMachine learning can be broadly categorized into three types. Supervised learning involves training \\nmodels on labeled data, where each training example is paired with an output label. This approach is \\ncommonly used in tasks such as spam detection, fraud detection, and recommendation systems.'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 0}, page_content='interacting with their environment and receiving rewards or penalties based on their actions. This \\napproach is often employed in robotics, game playing, and autonomous vehicles. \\nWhat is Deep Learning? \\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence')]\n",
            "\n",
            "Answer:\n",
            "Machine learning is a subset of artificial intelligence that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit programming. The process involves training models on datasets to identify patterns and make predictions or decisions.\n",
            "\n",
            "Types of Machine Learning:\n",
            "Machine learning can be broadly categorized into three types. Supervised learning involves training models on labeled data, where each training example is paired with an output label. This approach is commonly used in tasks such as spam detection, fraud\n"
          ]
        }
      ],
      "source": [
        "response = chain.invoke(\"What is Machine Learning?\")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7lvjjljHXsS"
      },
      "source": [
        "# KeywordRetriever, VectorstoreRetreiver, ensemble_retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaf_Mq55J9Bj",
        "outputId": "f76ae1e3-00b8-439c-d2a3-aec06f12fd5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "methodologies vary significantly. This document explores the fundamentals, differences, and \n",
            "applications of machine learning and deep learning. \n",
            "What is Machine Learning? \n",
            "Machine learning is a subset of AI that focuses on the development of algorithms and statistical models \n",
            "that enable computers to perform tasks without explicit programming. The process involves training\n",
            "---------------------\n",
            "interacting with their environment and receiving rewards or penalties based on their actions. This \n",
            "approach is often employed in robotics, game playing, and autonomous vehicles. \n",
            "What is Deep Learning? \n",
            "Deep learning is a subset of machine learning that employs neural networks with many layers (hence\n",
            "---------------------\n"
          ]
        }
      ],
      "source": [
        "for doc in KeywordRetriever.invoke(\"What is Machine Learning?\"):\n",
        "  print(doc.page_content)\n",
        "  print(\"---------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXpxejRqHdSa",
        "outputId": "f601d2b5-01a0-40cf-edec-923bd922ada3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models on datasets to identify patterns and make predictions or decisions. \n",
            "Types of Machine Learning \n",
            "Machine learning can be broadly categorized into three types. Supervised learning involves training \n",
            "models on labeled data, where each training example is paired with an output label. This approach is \n",
            "commonly used in tasks such as spam detection, fraud detection, and recommendation systems.\n",
            "---------------------\n",
            "methodologies vary significantly. This document explores the fundamentals, differences, and \n",
            "applications of machine learning and deep learning. \n",
            "What is Machine Learning? \n",
            "Machine learning is a subset of AI that focuses on the development of algorithms and statistical models \n",
            "that enable computers to perform tasks without explicit programming. The process involves training\n",
            "---------------------\n"
          ]
        }
      ],
      "source": [
        "for doc in VectorStoreRetriever.invoke(\"What is Machine Learning?\"):\n",
        "  print(doc.page_content)\n",
        "  print(\"---------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXBeg9ewHkP5",
        "outputId": "da63b852-73bf-4484-d580-504f611b99b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "methodologies vary significantly. This document explores the fundamentals, differences, and \n",
            "applications of machine learning and deep learning. \n",
            "What is Machine Learning? \n",
            "Machine learning is a subset of AI that focuses on the development of algorithms and statistical models \n",
            "that enable computers to perform tasks without explicit programming. The process involves training\n",
            "---------------------\n",
            "models on datasets to identify patterns and make predictions or decisions. \n",
            "Types of Machine Learning \n",
            "Machine learning can be broadly categorized into three types. Supervised learning involves training \n",
            "models on labeled data, where each training example is paired with an output label. This approach is \n",
            "commonly used in tasks such as spam detection, fraud detection, and recommendation systems.\n",
            "---------------------\n",
            "interacting with their environment and receiving rewards or penalties based on their actions. This \n",
            "approach is often employed in robotics, game playing, and autonomous vehicles. \n",
            "What is Deep Learning? \n",
            "Deep learning is a subset of machine learning that employs neural networks with many layers (hence\n",
            "---------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for doc in ensemble_retriever.invoke(\"What is Machine Learning?\"):\n",
        "  print(doc.page_content)\n",
        "  print(\"---------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcsLPZzzd2l7"
      },
      "source": [
        "# **Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3c9mA9OHvAr"
      },
      "outputs": [],
      "source": [
        "!pip install datasets==2.16.1 -q\n",
        "!pip install ragas==0.1.0 -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "uqV9XwAWeLRU",
        "outputId": "ad172d19-ca7f-4672-f735-eb372eaae3d7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"What is deep learning?\",\n          \"What are common uses of deep learning?\",\n          \"What is machine learning?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Deep learning is a subset of machine learning that uses neural networks with multiple layers to analyze complex patterns in large datasets.\",\n          \"Deep learning is used in computer vision, natural language processing, and autonomous systems like self-driving cars.\",\n          \"Machine learning is a subset of AI that develops algorithms enabling computers to learn from data and make decisions without explicit programming.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "test_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4fefdd68-e79b-4256-a6c9-ea9291d59934\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is machine learning?</td>\n",
              "      <td>Machine learning is a subset of AI that develo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is deep learning?</td>\n",
              "      <td>Deep learning is a subset of machine learning ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are the three types of machine learning?</td>\n",
              "      <td>The three types are supervised learning, unsup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is a neural network composed of?</td>\n",
              "      <td>A neural network consists of an input layer, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are some applications of machine learning?</td>\n",
              "      <td>Applications include healthcare (disease diagn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>What are common uses of deep learning?</td>\n",
              "      <td>Deep learning is used in computer vision, natu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is overfitting in machine learning?</td>\n",
              "      <td>Overfitting occurs when a model performs well ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is explainable AI (XAI)?</td>\n",
              "      <td>Explainable AI aims to make AI models, especia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fefdd68-e79b-4256-a6c9-ea9291d59934')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4fefdd68-e79b-4256-a6c9-ea9291d59934 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4fefdd68-e79b-4256-a6c9-ea9291d59934');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-22b85df3-0bdd-4850-9ecf-63b7d366e8f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-22b85df3-0bdd-4850-9ecf-63b7d366e8f8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-22b85df3-0bdd-4850-9ecf-63b7d366e8f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ea4a4ac8-9471-44da-ad79-e385afea8bf2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ea4a4ac8-9471-44da-ad79-e385afea8bf2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          Question  \\\n",
              "0                        What is machine learning?   \n",
              "1                           What is deep learning?   \n",
              "2    What are the three types of machine learning?   \n",
              "3            What is a neural network composed of?   \n",
              "4  What are some applications of machine learning?   \n",
              "5           What are common uses of deep learning?   \n",
              "6         What is overfitting in machine learning?   \n",
              "7                    What is explainable AI (XAI)?   \n",
              "\n",
              "                                              Answer  \n",
              "0  Machine learning is a subset of AI that develo...  \n",
              "1  Deep learning is a subset of machine learning ...  \n",
              "2  The three types are supervised learning, unsup...  \n",
              "3  A neural network consists of an input layer, o...  \n",
              "4  Applications include healthcare (disease diagn...  \n",
              "5  Deep learning is used in computer vision, natu...  \n",
              "6  Overfitting occurs when a model performs well ...  \n",
              "7  Explainable AI aims to make AI models, especia...  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_data = pd.read_csv(\"/content/Deep_Learning_ML_QA.csv\")\n",
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaOIPZs8gsdh"
      },
      "outputs": [],
      "source": [
        "question_list = test_data[\"Question\"].tolist()\n",
        "ground_truth_list = test_data[\"Answer\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV-Qu30hh8Qo",
        "outputId": "ef616c90-03ce-4e02-d2b5-dceeb00f8ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['What is machine learning?',\n",
              " 'What is deep learning?',\n",
              " 'What are the three types of machine learning?',\n",
              " 'What is a neural network composed of?',\n",
              " 'What are some applications of machine learning?',\n",
              " 'What are common uses of deep learning?',\n",
              " 'What is overfitting in machine learning?',\n",
              " 'What is explainable AI (XAI)?']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E82b5pliA7P",
        "outputId": "2a422be3-e60a-4ec6-867f-d39bdf716881"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Machine learning is a subset of AI that develops algorithms enabling computers to learn from data and make decisions without explicit programming.',\n",
              " 'Deep learning is a subset of machine learning that uses neural networks with multiple layers to analyze complex patterns in large datasets.',\n",
              " 'The three types are supervised learning, unsupervised learning, and reinforcement learning.',\n",
              " 'A neural network consists of an input layer, one or more hidden layers, and an output layer, with interconnected nodes performing computations.',\n",
              " 'Applications include healthcare (disease diagnosis), finance (credit scoring), and marketing (customer segmentation).',\n",
              " 'Deep learning is used in computer vision, natural language processing, and autonomous systems like self-driving cars.',\n",
              " 'Overfitting occurs when a model performs well on training data but poorly on unseen data.',\n",
              " 'Explainable AI aims to make AI models, especially deep learning models, more transparent and interpretable.']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBHG-kXPiHBH"
      },
      "outputs": [],
      "source": [
        "data = {\"question\": [] , \"answer\": [], \"contexts\":[], \"ground_truth\":ground_truth_list}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPKjj2WGiobY",
        "outputId": "7c646871-297f-40d4-dab4-738230e32ba5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-41-03be92556a3e>:4: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  data[\"contexts\"].append([doc.page_content for doc in ensemble_retriever.get_relevant_documents(query)])\n"
          ]
        }
      ],
      "source": [
        "for query in question_list:\n",
        "  data[\"question\"].append(query)\n",
        "  data[\"answer\"].append(chain.invoke(query))\n",
        "  data[\"contexts\"].append([doc.page_content for doc in ensemble_retriever.get_relevant_documents(query)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYfTRhDnjQkW",
        "outputId": "58ecbbe2-b8a0-4f30-849d-6680daa4137e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': ['What is machine learning?',\n",
              "  'What is deep learning?',\n",
              "  'What are the three types of machine learning?',\n",
              "  'What is a neural network composed of?',\n",
              "  'What are some applications of machine learning?',\n",
              "  'What are common uses of deep learning?',\n",
              "  'What is overfitting in machine learning?',\n",
              "  'What is explainable AI (XAI)?'],\n",
              " 'answer': [\"Human: \\nAnswer this question using the provided context only.\\n\\nWhat is machine learning?\\n\\nContext:\\n[Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training'), Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='models on datasets to identify patterns and make predictions or decisions. \\\\nTypes of Machine Learning \\\\nMachine learning can be broadly categorized into three types. Supervised learning involves training \\\\nmodels on labeled data, where each training example is paired with an output label. This approach is \\\\ncommonly used in tasks such as spam detection, fraud detection, and recommendation systems.'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 0}, page_content='interacting with their environment and receiving rewards or penalties based on their actions. This \\\\napproach is often employed in robotics, game playing, and autonomous vehicles. \\\\nWhat is Deep Learning? \\\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence')]\\n\\nAnswer:\\nMachine learning is a subset of artificial intelligence that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit programming. The process involves training models on datasets to identify patterns and make predictions or decisions.\\n\\nMachine learning can be broadly categorized into three types: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves training models on labeled data, where each training example is paired with an output label. This approach is commonly used in\",\n",
              "  'Human: \\nAnswer this question using the provided context only.\\n\\nWhat is deep learning?\\n\\nContext:\\n[Document(metadata={\\'page\\': 0, \\'source\\': \\'/content/Deep_Learning_Machine_Learning_Updated.pdf\\'}, page_content=\\'interacting with their environment and receiving rewards or penalties based on their actions. This \\\\napproach is often employed in robotics, game playing, and autonomous vehicles. \\\\nWhat is Deep Learning? \\\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence\\'), Document(metadata={\\'page\\': 0, \\'source\\': \\'/content/Deep_Learning_Machine_Learning_Updated.pdf\\'}, page_content=\\'methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training\\')]\\n\\nAnswer:\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence the name \"deep\") to learn complex patterns in data. It is a powerful tool for solving a wide range of problems, including image recognition, natural language processing, and speech recognition.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
              "  \"Human: \\nAnswer this question using the provided context only.\\n\\nWhat are the three types of machine learning?\\n\\nContext:\\n[Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training'), Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='models on datasets to identify patterns and make predictions or decisions. \\\\nTypes of Machine Learning \\\\nMachine learning can be broadly categorized into three types. Supervised learning involves training \\\\nmodels on labeled data, where each training example is paired with an output label. This approach is \\\\ncommonly used in tasks such as spam detection, fraud detection, and recommendation systems.'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 0}, page_content='interacting with their environment and receiving rewards or penalties based on their actions. This \\\\napproach is often employed in robotics, game playing, and autonomous vehicles. \\\\nWhat is Deep Learning? \\\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence')]\\n\\nAnswer:\\nThe three types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\\n\\nSupervised learning involves training a model on labeled data, where each training example is paired with an output label. This approach is commonly used in tasks such as spam detection, fraud detection, and recommendation systems.\\n\\nUnsupervised learning involves training a model on unlabeled data, where the model is tasked with identifying patterns and structures in the data. This approach is\",\n",
              "  'Human: \\nAnswer this question using the provided context only.\\n\\nWhat is a neural network composed of?\\n\\nContext:\\n[Document(metadata={\\'page\\': 0, \\'source\\': \\'/content/Deep_Learning_Machine_Learning_Updated.pdf\\'}, page_content=\\'\"deep\") to model and understand complex patterns in large datasets. Deep learning is particularly \\\\neffective for tasks that require high-level feature extraction. Neural networks, the backbone of deep \\\\nlearning, are composed of interconnected layers of nodes. The input layer accepts raw data, while\\'), Document(metadata={\\'page\\': 0, \\'source\\': \\'/content/Deep_Learning_Machine_Learning_Updated.pdf\\'}, page_content=\\'hidden layers perform computations to extract features and patterns. The output layer produces the \\\\nfinal result, such as a classification or prediction. Each node in a layer is connected to nodes in the \\\\nsubsequent layer, with each connection assigned a weight. During training, these weights are adjusted to \\\\nminimize error using optimization techniques such as stochastic gradient descent.\\'), Document(metadata={\\'source\\': \\'/content/Deep_Learning_Machine_Learning_Updated.pdf\\', \\'page\\': 0}, page_content=\\'interacting with their environment and receiving rewards or penalties based on their actions. This \\\\napproach is often employed in robotics, game playing, and autonomous vehicles. \\\\nWhat is Deep Learning? \\\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence\\'), Document(metadata={\\'source\\': \\'/content/Deep_Learning_Machine_Learning_Updated.pdf\\', \\'page\\': 0}, page_content=\\'methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training\\')]\\n\\nAnswer:\\nNeural networks are composed of interconnected layers of nodes, where each node represents a processing unit that performs computations on the input data. The input layer accepts raw data, while the hidden layers perform computations to extract features and patterns. The output layer produces the final result, such as a classification or prediction. Each node in a layer is connected to nodes in the subsequent layer, with each connection assigned a weight. During training, these weights are adjusted to minimize error using optimization techniques such as st',\n",
              "  \"Human: \\nAnswer this question using the provided context only.\\n\\nWhat are some applications of machine learning?\\n\\nContext:\\n[Document(metadata={'page': 1, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='Machine learning is widely used across various domains. In healthcare, it helps in predicting patient \\\\noutcomes, diagnosing diseases, and enabling personalized medicine. In finance, machine learning \\\\nalgorithms are used for credit scoring, algorithmic trading, and risk assessment. Marketing also benefits \\\\nfrom machine learning through customer segmentation, churn prediction, and recommendation'), Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='Applications of Machine Learning and Deep Learning \\\\nMachine Learning Applications'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 0}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 1}, page_content='well on training data but poorly on unseen data. Bias and fairness are also significant concerns, as \\\\nalgorithms can inherit biases present in the training data. Additionally, some machine learning models, \\\\nsuch as ensembles, lack transparency, making them difficult to interpret. \\\\nDeep Learning Challenges')]\\n\\nAnswer:\\nMachine learning has a wide range of applications in various domains, including healthcare, finance, marketing, and more. In healthcare, machine learning algorithms are used for predicting patient outcomes, diagnosing diseases, and enabling personalized medicine. In finance, machine learning algorithms are used for credit scoring, algorithmic trading, and risk assessment. Marketing also benefits from machine learning through customer segmentation, churn prediction, and recommendation.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\n",
              "  \"Human: \\nAnswer this question using the provided context only.\\n\\nWhat are common uses of deep learning?\\n\\nContext:\\n[Document(metadata={'page': 1, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='engines. \\\\nDeep Learning Applications \\\\nDeep learning has proven to be highly effective in domains requiring complex data analysis. In computer \\\\nvision, it is used for object detection, facial recognition, and medical imaging. In natural language \\\\nprocessing (NLP), deep learning powers language translation, sentiment analysis, and chatbots.'), Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='Applications of Machine Learning and Deep Learning \\\\nMachine Learning Applications'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 1}, page_content='Autonomous systems, such as self-driving cars, drones, and robotics, also rely heavily on deep learning \\\\nfor decision-making and navigation. \\\\nChallenges and Limitations \\\\nMachine Learning Challenges \\\\nMachine learning models face several challenges. Overfitting is a common issue where models perform'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 0}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training')]\\n\\nAnswer:\\nDeep learning is a subset of machine learning that uses artificial neural networks to learn from data and make predictions. It has been used in various applications such as image recognition, natural language processing, and speech recognition.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\n",
              "  \"Human: \\nAnswer this question using the provided context only.\\n\\nWhat is overfitting in machine learning?\\n\\nContext:\\n[Document(metadata={'page': 1, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='Autonomous systems, such as self-driving cars, drones, and robotics, also rely heavily on deep learning \\\\nfor decision-making and navigation. \\\\nChallenges and Limitations \\\\nMachine Learning Challenges \\\\nMachine learning models face several challenges. Overfitting is a common issue where models perform'), Document(metadata={'page': 1, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='well on training data but poorly on unseen data. Bias and fairness are also significant concerns, as \\\\nalgorithms can inherit biases present in the training data. Additionally, some machine learning models, \\\\nsuch as ensembles, lack transparency, making them difficult to interpret. \\\\nDeep Learning Challenges'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 0}, page_content='interacting with their environment and receiving rewards or penalties based on their actions. This \\\\napproach is often employed in robotics, game playing, and autonomous vehicles. \\\\nWhat is Deep Learning? \\\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 0}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training')]\\n\\nAnswer:\\nOverfitting in machine learning refers to a situation where a model performs well on the training data but poorly on unseen data. It occurs when the model is too complex and memorizes the training data instead of learning generalizable patterns. Overfitting can lead to poor generalization and high variance in model performance.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\n",
              "  \"Human: \\nAnswer this question using the provided context only.\\n\\nWhat is explainable AI (XAI)?\\n\\nContext:\\n[Document(metadata={'page': 1, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='Advancements in Deep Learning \\\\nDeep learning is also witnessing significant advancements. Transformer architectures, such as GPT and \\\\nBERT, have revolutionized NLP tasks. Efforts are being made to develop explainable AI (XAI) to make deep \\\\nlearning models more interpretable and transparent. Additionally, researchers are focusing on improving'), Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='interacting with their environment and receiving rewards or penalties based on their actions. This \\\\napproach is often employed in robotics, game playing, and autonomous vehicles. \\\\nWhat is Deep Learning? \\\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 0}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training')]\\n\\nAnswer:\\nExplainable AI (XAI) is a branch of artificial intelligence that aims to make machine learning models more interpretable and transparent. It involves developing techniques and tools that can explain the decisions and predictions made by machine learning models in a way that is understandable to humans. The goal of XAI is to improve the trust and acceptance of machine learning models in real-world applications, where transparency and explainability are crucial for decision-making and regulatory compliance.\"],\n",
              " 'contexts': [['methodologies vary significantly. This document explores the fundamentals, differences, and \\napplications of machine learning and deep learning. \\nWhat is Machine Learning? \\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\nthat enable computers to perform tasks without explicit programming. The process involves training',\n",
              "   'models on datasets to identify patterns and make predictions or decisions. \\nTypes of Machine Learning \\nMachine learning can be broadly categorized into three types. Supervised learning involves training \\nmodels on labeled data, where each training example is paired with an output label. This approach is \\ncommonly used in tasks such as spam detection, fraud detection, and recommendation systems.',\n",
              "   'interacting with their environment and receiving rewards or penalties based on their actions. This \\napproach is often employed in robotics, game playing, and autonomous vehicles. \\nWhat is Deep Learning? \\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence'],\n",
              "  ['interacting with their environment and receiving rewards or penalties based on their actions. This \\napproach is often employed in robotics, game playing, and autonomous vehicles. \\nWhat is Deep Learning? \\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence',\n",
              "   'methodologies vary significantly. This document explores the fundamentals, differences, and \\napplications of machine learning and deep learning. \\nWhat is Machine Learning? \\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\nthat enable computers to perform tasks without explicit programming. The process involves training'],\n",
              "  ['methodologies vary significantly. This document explores the fundamentals, differences, and \\napplications of machine learning and deep learning. \\nWhat is Machine Learning? \\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\nthat enable computers to perform tasks without explicit programming. The process involves training',\n",
              "   'models on datasets to identify patterns and make predictions or decisions. \\nTypes of Machine Learning \\nMachine learning can be broadly categorized into three types. Supervised learning involves training \\nmodels on labeled data, where each training example is paired with an output label. This approach is \\ncommonly used in tasks such as spam detection, fraud detection, and recommendation systems.',\n",
              "   'interacting with their environment and receiving rewards or penalties based on their actions. This \\napproach is often employed in robotics, game playing, and autonomous vehicles. \\nWhat is Deep Learning? \\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence'],\n",
              "  ['\"deep\") to model and understand complex patterns in large datasets. Deep learning is particularly \\neffective for tasks that require high-level feature extraction. Neural networks, the backbone of deep \\nlearning, are composed of interconnected layers of nodes. The input layer accepts raw data, while',\n",
              "   'hidden layers perform computations to extract features and patterns. The output layer produces the \\nfinal result, such as a classification or prediction. Each node in a layer is connected to nodes in the \\nsubsequent layer, with each connection assigned a weight. During training, these weights are adjusted to \\nminimize error using optimization techniques such as stochastic gradient descent.',\n",
              "   'interacting with their environment and receiving rewards or penalties based on their actions. This \\napproach is often employed in robotics, game playing, and autonomous vehicles. \\nWhat is Deep Learning? \\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence',\n",
              "   'methodologies vary significantly. This document explores the fundamentals, differences, and \\napplications of machine learning and deep learning. \\nWhat is Machine Learning? \\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\nthat enable computers to perform tasks without explicit programming. The process involves training'],\n",
              "  ['Machine learning is widely used across various domains. In healthcare, it helps in predicting patient \\noutcomes, diagnosing diseases, and enabling personalized medicine. In finance, machine learning \\nalgorithms are used for credit scoring, algorithmic trading, and risk assessment. Marketing also benefits \\nfrom machine learning through customer segmentation, churn prediction, and recommendation',\n",
              "   'Applications of Machine Learning and Deep Learning \\nMachine Learning Applications',\n",
              "   'methodologies vary significantly. This document explores the fundamentals, differences, and \\napplications of machine learning and deep learning. \\nWhat is Machine Learning? \\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\nthat enable computers to perform tasks without explicit programming. The process involves training',\n",
              "   'well on training data but poorly on unseen data. Bias and fairness are also significant concerns, as \\nalgorithms can inherit biases present in the training data. Additionally, some machine learning models, \\nsuch as ensembles, lack transparency, making them difficult to interpret. \\nDeep Learning Challenges'],\n",
              "  ['engines. \\nDeep Learning Applications \\nDeep learning has proven to be highly effective in domains requiring complex data analysis. In computer \\nvision, it is used for object detection, facial recognition, and medical imaging. In natural language \\nprocessing (NLP), deep learning powers language translation, sentiment analysis, and chatbots.',\n",
              "   'Applications of Machine Learning and Deep Learning \\nMachine Learning Applications',\n",
              "   'Autonomous systems, such as self-driving cars, drones, and robotics, also rely heavily on deep learning \\nfor decision-making and navigation. \\nChallenges and Limitations \\nMachine Learning Challenges \\nMachine learning models face several challenges. Overfitting is a common issue where models perform',\n",
              "   'methodologies vary significantly. This document explores the fundamentals, differences, and \\napplications of machine learning and deep learning. \\nWhat is Machine Learning? \\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\nthat enable computers to perform tasks without explicit programming. The process involves training'],\n",
              "  ['Autonomous systems, such as self-driving cars, drones, and robotics, also rely heavily on deep learning \\nfor decision-making and navigation. \\nChallenges and Limitations \\nMachine Learning Challenges \\nMachine learning models face several challenges. Overfitting is a common issue where models perform',\n",
              "   'well on training data but poorly on unseen data. Bias and fairness are also significant concerns, as \\nalgorithms can inherit biases present in the training data. Additionally, some machine learning models, \\nsuch as ensembles, lack transparency, making them difficult to interpret. \\nDeep Learning Challenges',\n",
              "   'interacting with their environment and receiving rewards or penalties based on their actions. This \\napproach is often employed in robotics, game playing, and autonomous vehicles. \\nWhat is Deep Learning? \\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence',\n",
              "   'methodologies vary significantly. This document explores the fundamentals, differences, and \\napplications of machine learning and deep learning. \\nWhat is Machine Learning? \\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\nthat enable computers to perform tasks without explicit programming. The process involves training'],\n",
              "  ['Advancements in Deep Learning \\nDeep learning is also witnessing significant advancements. Transformer architectures, such as GPT and \\nBERT, have revolutionized NLP tasks. Efforts are being made to develop explainable AI (XAI) to make deep \\nlearning models more interpretable and transparent. Additionally, researchers are focusing on improving',\n",
              "   'interacting with their environment and receiving rewards or penalties based on their actions. This \\napproach is often employed in robotics, game playing, and autonomous vehicles. \\nWhat is Deep Learning? \\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence',\n",
              "   'methodologies vary significantly. This document explores the fundamentals, differences, and \\napplications of machine learning and deep learning. \\nWhat is Machine Learning? \\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\nthat enable computers to perform tasks without explicit programming. The process involves training']],\n",
              " 'ground_truth': ['Machine learning is a subset of AI that develops algorithms enabling computers to learn from data and make decisions without explicit programming.',\n",
              "  'Deep learning is a subset of machine learning that uses neural networks with multiple layers to analyze complex patterns in large datasets.',\n",
              "  'The three types are supervised learning, unsupervised learning, and reinforcement learning.',\n",
              "  'A neural network consists of an input layer, one or more hidden layers, and an output layer, with interconnected nodes performing computations.',\n",
              "  'Applications include healthcare (disease diagnosis), finance (credit scoring), and marketing (customer segmentation).',\n",
              "  'Deep learning is used in computer vision, natural language processing, and autonomous systems like self-driving cars.',\n",
              "  'Overfitting occurs when a model performs well on training data but poorly on unseen data.',\n",
              "  'Explainable AI aims to make AI models, especially deep learning models, more transparent and interpretable.']}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz29zF9Im8bk"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset = Dataset.from_dict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnDbqU54kXjW",
        "outputId": "87d9c7d8-3179-4430-b258-4a0de60ebf52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['question', 'answer', 'contexts', 'ground_truth'],\n",
              "    num_rows: 8\n",
              "})"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbRzVF21qDv6"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = userdata.get('Open_AI_API_Key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7ded9b69299e40a9a5b32642fdfaa017",
            "46ba47cd2e6f4b4891c49db3212af756",
            "27e3e35160a942dbac3e0f90e286b4de",
            "3a0968429ad74053b7c5af9924dbded4",
            "bd3fbbe3fc274793aa51ae378440be07",
            "49d897bd4f3a499d94dc0ef566af6f0f",
            "579660a4d91241fb9f439729d4582f93",
            "09cf33910bbd43fcad503c845e274da4",
            "58003494799a44ad8a2075e5061959be",
            "9c7d95a6bb154d779817efd4778ef266",
            "7b6bc688f2214b3faf46c0e0573cfcb9"
          ]
        },
        "id": "CLWoB0qdoLc8",
        "outputId": "9058ff61-817e-4124-a6ae-f5e292931ed0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ded9b69299e40a9a5b32642fdfaa017"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_answer_relevance.py\", line 124, in _ascore\n",
            "    result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 110, in generate\n",
            "    return await loop.run_in_executor(None, generate_text)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
            "    return copy(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 475, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 376, in iter\n",
            "    result = action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 478, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 139, in generate_text\n",
            "    return self.langchain_llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 717, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 859, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1280, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 957, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1061, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_faithfulness.py\", line 180, in _ascore\n",
            "    answer_result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 110, in generate\n",
            "    return await loop.run_in_executor(None, generate_text)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
            "    return copy(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 475, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 376, in iter\n",
            "    result = action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 478, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 139, in generate_text\n",
            "    return self.langchain_llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 717, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 859, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1280, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 957, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1061, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_answer_relevance.py\", line 124, in _ascore\n",
            "    result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 110, in generate\n",
            "    return await loop.run_in_executor(None, generate_text)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
            "    return copy(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 475, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 376, in iter\n",
            "    result = action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 478, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 139, in generate_text\n",
            "    return self.langchain_llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 717, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 859, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1280, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 957, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1061, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_context_precision.py\", line 129, in _ascore\n",
            "    result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 110, in generate\n",
            "    return await loop.run_in_executor(None, generate_text)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
            "    return copy(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 475, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 376, in iter\n",
            "    result = action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 478, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 139, in generate_text\n",
            "    return self.langchain_llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 717, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 859, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1280, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 957, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1061, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_faithfulness.py\", line 180, in _ascore\n",
            "    answer_result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 110, in generate\n",
            "    return await loop.run_in_executor(None, generate_text)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
            "    return copy(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 475, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 376, in iter\n",
            "    result = action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 478, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 139, in generate_text\n",
            "    return self.langchain_llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 717, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 859, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1280, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 957, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1061, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_context_precision.py\", line 129, in _ascore\n",
            "    result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 110, in generate\n",
            "    return await loop.run_in_executor(None, generate_text)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
            "    return copy(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 475, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 376, in iter\n",
            "    result = action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 478, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 139, in generate_text\n",
            "    return self.langchain_llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 717, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 859, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1280, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 957, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1061, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_answer_relevance.py\", line 124, in _ascore\n",
            "    result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 110, in generate\n",
            "    return await loop.run_in_executor(None, generate_text)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
            "    return copy(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 475, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 376, in iter\n",
            "    result = action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 478, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 139, in generate_text\n",
            "    return self.langchain_llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 717, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 859, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1280, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 957, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1061, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_context_precision.py\", line 129, in _ascore\n",
            "    result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 110, in generate\n",
            "    return await loop.run_in_executor(None, generate_text)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
            "    return copy(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 475, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 376, in iter\n",
            "    result = action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 478, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 139, in generate_text\n",
            "    return self.langchain_llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 717, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 859, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1280, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 957, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1061, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_context_recall.py\", line 115, in _ascore\n",
            "    result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 92, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 169, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 796, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 756, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 924, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 853, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 1720, in create\n",
            "    return await self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1843, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1537, in request\n",
            "    return await self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1623, in _request\n",
            "    return await self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
            "    return await self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1623, in _request\n",
            "    return await self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
            "    return await self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1638, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_context_recall.py\", line 115, in _ascore\n",
            "    result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 92, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 169, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 796, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 756, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 924, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 853, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 1720, in create\n",
            "    return await self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1843, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1537, in request\n",
            "    return await self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1623, in _request\n",
            "    return await self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
            "    return await self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1623, in _request\n",
            "    return await self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
            "    return await self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1638, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_context_recall.py\", line 115, in _ascore\n",
            "    result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 92, in generate\n",
            "    return await agenerate_text_with_retry(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 169, in agenerate_text\n",
            "    return await self.langchain_llm.agenerate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 796, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 756, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 924, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 853, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 1720, in create\n",
            "    return await self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1843, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1537, in request\n",
            "    return await self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1623, in _request\n",
            "    return await self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
            "    return await self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1623, in _request\n",
            "    return await self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1670, in _retry_request\n",
            "    return await self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1638, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:ragas.executor:Runner in Executor raised an exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 58, in _aresults\n",
            "    r = await future\n",
            "  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 571, in _wait_for_one\n",
            "    return f.result()  # May raise f.exception().\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/executor.py\", line 91, in wrapped_callable_async\n",
            "    return counter, await callable(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 91, in ascore\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py\", line 87, in ascore\n",
            "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/metrics/_faithfulness.py\", line 180, in _ascore\n",
            "    answer_result = await self.llm.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 110, in generate\n",
            "    return await loop.run_in_executor(None, generate_text)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 336, in wrapped_f\n",
            "    return copy(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 475, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 376, in iter\n",
            "    result = action(retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\", line 478, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py\", line 139, in generate_text\n",
            "    return self.langchain_llm.generate_prompt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py\", line 717, in _generate\n",
            "    response = self.client.create(**payload)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\", line 859, in create\n",
            "    return self._post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1280, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 957, in request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1046, in _request\n",
            "    return self._retry_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
            "    return self._request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\", line 1061, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        }
      ],
      "source": [
        "# Create a smaller subset for testing\n",
        "small_dataset = dataset.select(range(3))  # Select the first 5 entries\n",
        "result = evaluate(\n",
        "    dataset=small_dataset,\n",
        "    metrics=[context_precision, context_recall, answer_relevancy, faithfulness],\n",
        "    raise_exceptions=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD2uqi5Joidr",
        "outputId": "e51a9a33-a187-45dc-cf55-460f7a4595cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_precision': nan, 'context_recall': nan, 'answer_relevancy': nan, 'faithfulness': nan}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "pyQiDjDir92J",
        "outputId": "7f3ce87b-cbdc-4883-f73f-5e4bc65b01a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        question  \\\n",
              "0                      What is machine learning?   \n",
              "1                         What is deep learning?   \n",
              "2  What are the three types of machine learning?   \n",
              "\n",
              "                                              answer  \\\n",
              "0  Human: \\nAnswer this question using the provid...   \n",
              "1  Human: \\nAnswer this question using the provid...   \n",
              "2  Human: \\nAnswer this question using the provid...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [methodologies vary significantly. This docume...   \n",
              "1  [interacting with their environment and receiv...   \n",
              "2  [methodologies vary significantly. This docume...   \n",
              "\n",
              "                                        ground_truth  context_precision  \\\n",
              "0  Machine learning is a subset of AI that develo...                NaN   \n",
              "1  Deep learning is a subset of machine learning ...                NaN   \n",
              "2  The three types are supervised learning, unsup...                NaN   \n",
              "\n",
              "   context_recall  answer_relevancy  faithfulness  \n",
              "0             NaN               NaN           NaN  \n",
              "1             NaN               NaN           NaN  \n",
              "2             NaN               NaN           NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb56ad1e-998f-4640-9436-2230fb930d26\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>faithfulness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is machine learning?</td>\n",
              "      <td>Human: \\nAnswer this question using the provid...</td>\n",
              "      <td>[methodologies vary significantly. This docume...</td>\n",
              "      <td>Machine learning is a subset of AI that develo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is deep learning?</td>\n",
              "      <td>Human: \\nAnswer this question using the provid...</td>\n",
              "      <td>[interacting with their environment and receiv...</td>\n",
              "      <td>Deep learning is a subset of machine learning ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are the three types of machine learning?</td>\n",
              "      <td>Human: \\nAnswer this question using the provid...</td>\n",
              "      <td>[methodologies vary significantly. This docume...</td>\n",
              "      <td>The three types are supervised learning, unsup...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb56ad1e-998f-4640-9436-2230fb930d26')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb56ad1e-998f-4640-9436-2230fb930d26 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb56ad1e-998f-4640-9436-2230fb930d26');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6731ca4d-b978-4aeb-866a-38339df00b87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6731ca4d-b978-4aeb-866a-38339df00b87')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6731ca4d-b978-4aeb-866a-38339df00b87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8d0424ca-677b-4def-a7a9-5c379566433a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8d0424ca-677b-4def-a7a9-5c379566433a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"What is machine learning?\",\n          \"What is deep learning?\",\n          \"What are the three types of machine learning?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Human: \\nAnswer this question using the provided context only.\\n\\nWhat is machine learning?\\n\\nContext:\\n[Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training'), Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='models on datasets to identify patterns and make predictions or decisions. \\\\nTypes of Machine Learning \\\\nMachine learning can be broadly categorized into three types. Supervised learning involves training \\\\nmodels on labeled data, where each training example is paired with an output label. This approach is \\\\ncommonly used in tasks such as spam detection, fraud detection, and recommendation systems.'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 0}, page_content='interacting with their environment and receiving rewards or penalties based on their actions. This \\\\napproach is often employed in robotics, game playing, and autonomous vehicles. \\\\nWhat is Deep Learning? \\\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence')]\\n\\nAnswer:\\nMachine learning is a subset of artificial intelligence that focuses on the development of algorithms and statistical models that enable computers to perform tasks without explicit programming. The process involves training models on datasets to identify patterns and make predictions or decisions.\\n\\nMachine learning can be broadly categorized into three types: supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves training models on labeled data, where each training example is paired with an output label. This approach is commonly used in\",\n          \"Human: \\nAnswer this question using the provided context only.\\n\\nWhat is deep learning?\\n\\nContext:\\n[Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='interacting with their environment and receiving rewards or penalties based on their actions. This \\\\napproach is often employed in robotics, game playing, and autonomous vehicles. \\\\nWhat is Deep Learning? \\\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence'), Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training')]\\n\\nAnswer:\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence the name \\\"deep\\\") to learn complex patterns in data. It is a powerful tool for solving a wide range of problems, including image recognition, natural language processing, and speech recognition.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\",\n          \"Human: \\nAnswer this question using the provided context only.\\n\\nWhat are the three types of machine learning?\\n\\nContext:\\n[Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='methodologies vary significantly. This document explores the fundamentals, differences, and \\\\napplications of machine learning and deep learning. \\\\nWhat is Machine Learning? \\\\nMachine learning is a subset of AI that focuses on the development of algorithms and statistical models \\\\nthat enable computers to perform tasks without explicit programming. The process involves training'), Document(metadata={'page': 0, 'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf'}, page_content='models on datasets to identify patterns and make predictions or decisions. \\\\nTypes of Machine Learning \\\\nMachine learning can be broadly categorized into three types. Supervised learning involves training \\\\nmodels on labeled data, where each training example is paired with an output label. This approach is \\\\ncommonly used in tasks such as spam detection, fraud detection, and recommendation systems.'), Document(metadata={'source': '/content/Deep_Learning_Machine_Learning_Updated.pdf', 'page': 0}, page_content='interacting with their environment and receiving rewards or penalties based on their actions. This \\\\napproach is often employed in robotics, game playing, and autonomous vehicles. \\\\nWhat is Deep Learning? \\\\nDeep learning is a subset of machine learning that employs neural networks with many layers (hence')]\\n\\nAnswer:\\nThe three types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\\n\\nSupervised learning involves training a model on labeled data, where each training example is paired with an output label. This approach is commonly used in tasks such as spam detection, fraud detection, and recommendation systems.\\n\\nUnsupervised learning involves training a model on unlabeled data, where the model is tasked with identifying patterns and structures in the data. This approach is\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Machine learning is a subset of AI that develops algorithms enabling computers to learn from data and make decisions without explicit programming.\",\n          \"Deep learning is a subset of machine learning that uses neural networks with multiple layers to analyze complex patterns in large datasets.\",\n          \"The three types are supervised learning, unsupervised learning, and reinforcement learning.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_relevancy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"faithfulness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "results = result.to_pandas()\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "4ha7xLJ8sHNw",
        "outputId": "04563e63-0e0d-44c2-9111-ef8e6b2ea81c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "heatmap_data = results[['context_precision', 'context_recall', 'answer_relevancy', 'faithfulness']]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", linewidths=.5)\n",
        "\n",
        "plt.yticks(ticks=range(len(results['question'])), labels=results['question'], rotation=0)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2R3VFiasTqC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ded9b69299e40a9a5b32642fdfaa017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46ba47cd2e6f4b4891c49db3212af756",
              "IPY_MODEL_27e3e35160a942dbac3e0f90e286b4de",
              "IPY_MODEL_3a0968429ad74053b7c5af9924dbded4"
            ],
            "layout": "IPY_MODEL_bd3fbbe3fc274793aa51ae378440be07"
          }
        },
        "46ba47cd2e6f4b4891c49db3212af756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49d897bd4f3a499d94dc0ef566af6f0f",
            "placeholder": "​",
            "style": "IPY_MODEL_579660a4d91241fb9f439729d4582f93",
            "value": "Evaluating: 100%"
          }
        },
        "27e3e35160a942dbac3e0f90e286b4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09cf33910bbd43fcad503c845e274da4",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58003494799a44ad8a2075e5061959be",
            "value": 12
          }
        },
        "3a0968429ad74053b7c5af9924dbded4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c7d95a6bb154d779817efd4778ef266",
            "placeholder": "​",
            "style": "IPY_MODEL_7b6bc688f2214b3faf46c0e0573cfcb9",
            "value": " 12/12 [04:37&lt;00:00, 10.77s/it]"
          }
        },
        "bd3fbbe3fc274793aa51ae378440be07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d897bd4f3a499d94dc0ef566af6f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "579660a4d91241fb9f439729d4582f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09cf33910bbd43fcad503c845e274da4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58003494799a44ad8a2075e5061959be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c7d95a6bb154d779817efd4778ef266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b6bc688f2214b3faf46c0e0573cfcb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}